{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorio 7 - Aprendizaje Estadistico\n",
        "\n",
        "Por: Nicolas Osorno Roa"
      ],
      "metadata": {
        "id": "Lbu3vSsDejAe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FYoB1x47dfRE"
      },
      "outputs": [],
      "source": [
        "# 1. construccion de la capa L usando objetos, con todas las funciones necesarias\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class layer_nn():\n",
        "\n",
        "  def __init__(self, act_fun, nlayer_presente, nlayer_before):\n",
        "\n",
        "      self.theta = 2 * np.random.random((nlayer_presente, nlayer_before)) - 1\n",
        "      self.B = 2 * np.random.random((nlayer_presente, 1)) - 1\n",
        "      self.act_fun = act_fun\n",
        "\n",
        "  def forward(self, entrada):\n",
        "      self.entrada = entrada\n",
        "      self.z = np.dot(self.theta, entrada) + self.B\n",
        "      self.a, self.dfz = act_f(self.z, self.act_fun)\n",
        "      return self.a\n",
        "\n",
        "\n",
        "  def backward(self, dz, m ,alpha = 0.01 ):\n",
        "\n",
        "\n",
        "     self.dtheta = np.dot(dz, self.entrada.T)/m\n",
        "\n",
        "     self.dB = np.sum(dz)/m\n",
        "\n",
        "\n",
        "     self.theta = self.theta - alpha*self.dtheta\n",
        "     self.B = self.B - alpha*self.dB\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Crear la red nueronal dada una topologia y funcion de activacion\n",
        "\n",
        "\n",
        "def act_f(x, activation):\n",
        "    if activation == \"sigmoid\":\n",
        "        a = 1 / (1 + np.exp(-x))\n",
        "        da = a * (1 - a)\n",
        "        return a, da\n",
        "\n",
        "def iniciar_nn(topologia, list_act_f):\n",
        "  nn = []\n",
        "  for i in range(1, len(topologia)):\n",
        "    nn.append(layer_nn(act_fun = list_act_f[i-1] , nlayer_presente = topologia[i], nlayer_before   = topologia[i-1]))\n",
        "  return nn\n",
        "\n",
        "def forward_pass(X_train,nn):   # 2. Arroja la salida de la red nuronal dados datos de entrada\n",
        "\n",
        "  a = X_train\n",
        "\n",
        "  for layer in nn:\n",
        "\n",
        "        a = layer.forward(a)\n",
        "\n",
        "\n",
        "  return a\n"
      ],
      "metadata": {
        "id": "YHP79H85gKVm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Definicion Funcion de coste dado unos valores esperados(Y) y una salida de la red (aL)\n",
        "\n",
        "def f_coste(Y, aL):\n",
        "\n",
        "    cost = - (1/np.shape(aL)[1]) * np.sum(Y * np.log(aL) + (1 - Y) * np.log(1 - aL))\n",
        "\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "AOM6sYEc-hQ0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. implementacion backward  para todas las capas de la red, ademas del entrnamiento de la misma(iterar el Backward )\n",
        "def backward_network(nn,  aL, Y, m, alpha):\n",
        "\n",
        "  da = -(np.divide(Y, aL) - np.divide(1 - Y, 1 - aL))\n",
        "  dz = da*nn[-1].dfz\n",
        "  dth = np.dot(dz, nn[-1].entrada.T)/m\n",
        "  db = np.sum(dz)/m\n",
        "\n",
        "  nn[-1].theta = nn[-1].theta - alpha*dth\n",
        "\n",
        "  nn[-1].B = nn[-1].B - alpha*db\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(len(nn)-2,-1, -1):\n",
        "\n",
        "    dz = np.dot(nn[i+1].theta.T,dz)*nn[i].dfz/m\n",
        "\n",
        "\n",
        "    da = nn[i].backward(dz,m , alpha)\n",
        "\n",
        "\n",
        "def entrenamiento(ep, alpha, X_train, y_train):\n",
        "  for i in range(ep):\n",
        "    aL = forward_pass(X_train.T,nn)\n",
        "    backward_network(nn, aL , y1_train, n1_samples, 0.1)\n",
        "\n",
        "\n",
        "def calcular_precision(A_predicciones, Y_etiquetas_reales):\n",
        "\n",
        "    Y_pred_binario = (A_predicciones >= 0.5).astype(int)\n",
        "\n",
        "    aciertos = (Y_pred_binario == Y_etiquetas_reales)\n",
        "\n",
        "    precision = np.mean(aciertos)\n",
        "\n",
        "    return precision\n"
      ],
      "metadata": {
        "id": "OmNtLUfyZYij"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo de los resultados de la red con el metodo de make moon de sklearn que es facil de implementar\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X1, y1 = make_moons(n_samples=500, noise=0.1, random_state=42)\n",
        "\n",
        "n1_samples, n1_features = X1.shape\n",
        "\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
        "\n",
        "topologia = [n1_features,32,32,1]                            #ejemplo\n",
        "act_fs = [\"sigmoid\", \"sigmoid\", \"sigmoid\"]\n",
        "\n",
        "nn = iniciar_nn(topologia, act_fs)\n",
        "\n",
        "entrenamiento(10000, 0.1, X1_train, y1_train)\n",
        "\n",
        "salida=forward_pass(X1_train.T, nn)\n",
        "\n",
        "salida_binario = []\n",
        "\n",
        "for el in forward_pass(X1_train.T, nn)[0]:  # convertir la salida en solucion binaria, para este caso de dos clases\n",
        "  if el > 0.5:\n",
        "    salida_binario.append(1)\n",
        "  else:\n",
        "    salida_binario.append(0)\n",
        "\n",
        "print(\"La presiscion de la red para predecir la clase de los datos de entrenamiento es:\",float(calcular_precision(np.array(salida_binario), y1_train)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCg56ghbr0MO",
        "outputId": "90051eb7-1270-4b34-e270-876941c82001"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La presiscion de la red para predecir la clase de los datos de entrenamiento es: 0.8625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "salida=forward_pass(X1_test.T, nn)\n",
        "\n",
        "salida_binario_test = []\n",
        "\n",
        "for el in forward_pass(X1_test.T, nn)[0]:\n",
        "  if el > 0.5:\n",
        "    salida_binario_test.append(1)\n",
        "  else:\n",
        "    salida_binario_test.append(0)\n",
        "\n",
        "\n",
        "\n",
        "print(\"La presiscion de la red para predecir la clase de los datos de entrenamiento es:\",float(calcular_precision(np.array(salida_binario_test), y1_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDtNko-djNVO",
        "outputId": "9e2e34a5-9141-46d3-8ae1-f186469321e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La presiscion de la red para predecir la clase de los datos de entrenamiento es: 0.86\n"
          ]
        }
      ]
    }
  ]
}