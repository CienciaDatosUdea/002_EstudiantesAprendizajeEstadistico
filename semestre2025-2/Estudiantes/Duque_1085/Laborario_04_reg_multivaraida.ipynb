{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4mkbkAnmYa4"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CienciaDatosUdea/002_EstudiantesAprendizajeEstadistico/blob/main/semestre2025-2/Laboratorios/Laboratorio_04_reg_multivariada_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiRIfl4W2cLM"
      },
      "source": [
        "# Regresion multivariada\n",
        "\n",
        "Supongamos que tenemos un conjunto de caracteristicas $X = X_1,X_2...X_j...X_n$ para realizar una  predicción $y$ con valores esperados $\\hat{y}$.  \n",
        "\n",
        "Cada X, puede ser escrito como:\n",
        " $X_1 = x_1^{(1)},x_1^{(2)}, x_1^{(3)}...x_1^{(m)}$,\n",
        "\n",
        " $X_2 = x_2^{(1)},x_2^{(2)}, x_2^{(3)}...x_2^{(m)}$,\n",
        "\n",
        " .\n",
        "\n",
        " .\n",
        "\n",
        " .\n",
        "\n",
        " $X_n = x_n^{(1)},x_n^{(2)}, x_n^{(3)}...x_n^{(m)}$.\n",
        "\n",
        "\n",
        "Siendo n el número de caracteristicas y m el número de datos de datos,\n",
        "$\\hat{y} = \\hat{y}_1^{(1)}, \\hat{y}_1^{(2)}...\\hat{y}_1^{(m)} $, el conjunto de datos etiquetados  y $y = y_1^{(1)}, y_1^{(2)}...y_1^{(m)} $ los valores predichos por un modelo\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Lo anterior puede ser resumido  como:\n",
        "\n",
        "\n",
        "\n",
        "|Training|$\\hat{y}$      | X_1  | X_2  |  .  | .|. |. | X_n|\n",
        "|--------|-------|------|------|-----|--|--|--|----|\n",
        "|1|$\\hat{y}_1^{1}$ | $x_1^{1}$|$x_2^{1}$| .  | .|. |. | $x_n^{1}$|\n",
        "|2|$\\hat{y}_1^{2}$ | $x_1^{2}$|$x_2^{2}$| .  | .|. |. | $x_n^{2}$|\n",
        "|.|.         | .        |.| .  | .|. |. | |\n",
        "|.|.         | .        |.| .  | .|. |. | |\n",
        "|.|.         | .        |.| .  | .|. |. | |\n",
        "|m|$\\hat{y}_1^{m}$ | $x_1^{m}$  |$x_2^{m}$| .  | .|. |. | $x_n^{m}$|\n",
        "\n",
        "\n",
        "y el el modelo puede ser ajustado como sigue:\n",
        "\n",
        "Para un solo conjunto de datos de entrenamiento tentemos que:\n",
        "\n",
        "$y = h(\\theta_0,\\theta_1,\\theta_2,...,\\theta_n ) = \\theta_0 + \\theta_1 x_1+\\theta_2 x_2 + \\theta_3 x_3 +...+ \\theta_n x_n $.\n",
        "\n",
        "\\begin{equation}\n",
        "h_{\\Theta}(x) = [\\theta_0,\\theta_1,...,\\theta_n ]\\begin{bmatrix}\n",
        "1\\\\\n",
        "x_1\\\\\n",
        "x_2\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        "x_n\\\\\n",
        "\\end{bmatrix} = \\Theta^T X\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "Para todo el conjunto de datos, tenemos que:\n",
        "\n",
        "Sea $\\Theta^T = [\\theta_0,\\theta_1,\\theta_2,...,\\theta_n]$ una matrix $1 \\times (n+1)$ y  \n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "X =\n",
        "\\begin{bmatrix}\n",
        "1& 1 & 1 & .&.&.&1\\\\\n",
        "x_1^{(1)}&x_1^{(2)} & x_1^{(3)} & .&.&.&x_1^{(m)}\\\\\n",
        ".&. & . &.&.&.& .\\\\\n",
        ".&. & . & .&.&.&.\\\\\n",
        ".&. & . & .&.&.&.\\\\\n",
        "x_n^{(1)}&x_n^{(2)} & x_n^{(3)} & .&.&.&x_n^{(m)}\\\\\n",
        "\\end{bmatrix}_{(n+1) \\times m}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "luego $h = \\Theta^{T} X $ con dimension $1\\times m$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "La anterior ecuación, es un hiperplano en $\\mathbb{R}^n$. Notese que en caso de tener una sola característica, la ecuación puede ser análizada según lo visto en la sesión de regresion lineal.\n",
        "\n",
        "\n",
        "Para la optimización, vamos a definir la función de coste **$J(\\theta_1,\\theta_2,\\theta_3, ...,\\theta_n )$** , como la función  asociada a la minima distancia entre dos puntos, según la metrica euclidiana.\n",
        "\n",
        "- Metrica Eculidiana\n",
        "\n",
        "\\begin{equation}\n",
        "J(\\theta_1,\\theta_2,\\theta_3, ...,\\theta_n )=\\frac{1}{2m} \\sum_{i=1}^m ( h_{\\Theta} (X)-\\hat{y}^{(i)})^2 =\\frac{1}{2m} \\sum_{i = 1}^m (\\Theta^{T} X - \\hat{y}^{(i)})^2\n",
        "\\end{equation}\n",
        "\n",
        "Otras métricas pueden ser definidas como sigue en la siguiente referencia.  [Metricas](https://jmlb.github.io/flashcards/2018/04/21/list_cost_functions_fo_neuralnets/).\n",
        "\n",
        "Nuestro objetivo será encontrar los valores mínimos\n",
        "$\\Theta = \\theta_0,\\theta_1,\\theta_2,...,\\theta_n$ que minimizan el error, respecto a los valores etiquetados y esperados $\\hat{y}$\n",
        "\n",
        "\n",
        "Para encontrar $\\Theta$ optimo, se necesita  minimizar la función de coste, que permite obtener los valores más cercanos,  esta minimización podrá ser realizada a través de diferentes metodos, el más conocido es el gradiente descendente.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5ApulK23HfL"
      },
      "source": [
        "\n",
        "## Gradiente descendente\n",
        "\n",
        "Consideremos la función de coste sin realizar el promedio  de funcion de coste:\n",
        "\\begin{equation}\n",
        "\\Lambda^T =\n",
        "\\begin{bmatrix}\n",
        "(\\theta_0 1 + \\theta_1 x_1^1+\\theta_2 x_2^1 + \\theta_3 x_3^1 +...+ \\theta_n x_n^1 - \\hat{y}^{1})^2 \\\\\n",
        "(\\theta_0 1+ \\theta_1 x_1^2+\\theta_2 x_2^2 + \\theta_3 x_3^2 +...+ \\theta_n x_n^2 - \\hat{y}^{2})^2\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        ".\\\\\n",
        "(\\theta_0 1 + \\theta_1 x_1^m+\\theta_2 x_2^m + \\theta_3 x_3^m +...+ \\theta_n x_n^m - \\hat{y}^{m})^2\\\\\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "$\\Lambda= [\\Lambda_1,\\Lambda_2, ...,\\Lambda_m]$\n",
        "\n",
        "$J = \\frac{1}{2m} \\sum_{i}^m \\Lambda_i $\n",
        "\n",
        "El gradiente descente, puede ser escrito como:\n",
        "\n",
        "\\begin{equation}\n",
        "\\Delta \\vec{\\Theta} =  - \\alpha \\nabla J(\\theta_0, \\theta_1,...,\\theta_n)\n",
        "\\end{equation}\n",
        "\n",
        "escogiendo el valor j-esimo tenemos que:\n",
        "\n",
        "\\begin{equation}\n",
        "\\theta_j :=  - \\alpha \\frac{\\partial J(\\theta_0, \\theta_1,...\\theta_j...,\\theta_n)}{\\partial \\theta_j}\n",
        "\\end{equation}\n",
        "\n",
        "Aplicando lo anterior a a función de coste asociada a la métrica ecuclidiana, tenemos que:\n",
        "\n",
        "Para $j = 0$,\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\theta_0 :=  - \\alpha \\frac{\\partial J(\\theta_0, \\theta_1,...\\theta_j...,\\theta_n)}{\\partial \\theta_0} = \\frac{1}{m}\\alpha \\sum_{i=1}^m (\\theta_j X_{ji} - \\hat{y}^{(i)}) 1\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "Para $0<j<n $\n",
        "\n",
        "\\begin{equation}\n",
        "\\theta_j :=  - \\alpha \\frac{\\partial J(\\theta_0, \\theta_1,...\\theta_j...,\\theta_n)}{\\partial \\theta_j} = \\frac{1}{m} \\alpha\\sum_{i=1}^m (\\theta_{j} X_{ji} - \\hat{y}^{(i)}) X_j\n",
        "\\end{equation}\n",
        "\n",
        "donde X_j es el vector de entrenamiento j-esimo.\n",
        "\n",
        "Lo  anterior puede ser generalizado como siguem, teniendo presente que $X_0 = \\vec{1}$\n",
        "\n",
        "\n",
        "Para $0\\leq j<n$,\n",
        "\n",
        "\\begin{equation}\n",
        "\\theta_j :=  - \\alpha \\frac{\\partial J(\\theta_0, \\theta_1,...\\theta_j...,\\theta_n)}{\\partial \\theta_j} = \\frac{1}{m} \\alpha\\sum_{i=1}^m (\\theta_j X_{ji} - \\hat{y}^{(i)}) X_j\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "# Vectorizando el grandiente descendete, tenemos que:\n",
        "\\begin{equation}\n",
        "\\nabla J = \\Lambda^T X\n",
        "\\end{equation}\n",
        "\n",
        "Luego:\n",
        "\n",
        "\\begin{equation}\n",
        "\\Theta_{i+1}=\\Theta_i-\\alpha \\nabla J_i\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eavd6K24VDP"
      },
      "source": [
        "# Laboratorio 04\n",
        "Objetivo: Programar una regresión multivariada\n",
        "\n",
        "\n",
        "1. Para simular un conjunto de características $x_1$ , $x_2$,..., $x_n$ trabajaremos en la primera parte con dos características de datos aleatorios que presentan un plano y mostraremos que los párametros optimizados se corresponden con el valor esperado.\n",
        "\n",
        "- Definir la ecuación  $y = 2.1*x_1 - 3.1*x_2$, y generar números aleatorios que pertenecen al plano.\n",
        "\n",
        "- Realizar un diagrama 3D de los puntos generados aleatoriamente.\n",
        "\n",
        "\n",
        "Nuestro objetivo será encontrar los valores $\\theta_0 = 0, \\theta_1=2.1, \\theta_1=3.1$ que mejor ajustar el plano, empleando cálculos vectorizados.\n",
        "\n",
        "2. Inicializar conjunto de parámetros $\\Theta$ de manera aleatoria.\n",
        "3. Construir la matrix X con dimensiones $(n+1, m)$, m es el numero de datos de entrenamiento y (n) el número de caracteristicas.\n",
        "4. Calcular la función de coste(revise cuidosamente las dimensiones de cada matriz):\n",
        "\n",
        "  - $h = \\Theta^{T} X $\n",
        "  - $\\Lambda= (h -Y) $\n",
        "  - $\\Lambda*= (h -Y)^2 $\n",
        "  - $\\Lambda= [\\Lambda_1,\\Lambda_2, ...,\\Lambda_m]$\n",
        "  - $J = \\frac{1}{2m} \\sum_{i}^m \\Lambda_i $\n",
        "\n",
        "5. Aplicar el gradiente descendente:\n",
        "  - Encontrar el gradiente.\n",
        "    $\\nabla J = \\Lambda X.T$\n",
        "  \n",
        "  - Actualizar los nuevos parametros:\n",
        "    $\\Theta_{n+1}=\\Theta_{n}-\\alpha\\nabla J$\n",
        "\n",
        "\n",
        "6. Iterar para encontrar los valores $\\Theta$ que se ajustan el plano.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "GQyqmQdYrmq1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Generación de los datos\n",
        "func_y = lambda x_1,x_2: 2.1*x_1 - 3.1*x_2\n",
        "\n",
        "n_datos = 100\n",
        "\n",
        "x_1 = np.random.random(n_datos)\n",
        "x_2 = np.random.random(n_datos)\n",
        "y = func_y(x_1,x_2)\n",
        "\n",
        "fig = go.Figure(data=[go.Scatter3d(x=x_1, y=x_2, z=y, mode='markers')])\n",
        "fig.update_layout(scene = dict(\n",
        "                    xaxis_title='x_1',\n",
        "                    yaxis_title='x_2',\n",
        "                    zaxis_title='y'),\n",
        "                    margin=dict(l=0, r=0, b=0, t=0))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "xV1W2KTnr0At",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "d0a296dd-dd14-4156-ddb7-62bdd87e2aec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b3c5ecda-77bf-43d9-bad4-d2814327f68b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b3c5ecda-77bf-43d9-bad4-d2814327f68b\")) {                    Plotly.newPlot(                        \"b3c5ecda-77bf-43d9-bad4-d2814327f68b\",                        [{\"mode\":\"markers\",\"x\":[0.1953899007364871,0.5479696835338415,0.47557431998957067,0.07995265889980663,0.5914508990172916,0.1822026622457934,0.4578130784387743,0.7740062976450565,0.08751370568188488,0.05922983332706544,0.18758238453140197,0.06020163379703458,0.860092426988014,0.5064188076758085,0.36185760420403756,0.23717257550058568,0.4197806851753364,0.17891706725004386,0.06312874930977885,0.07299357570688736,0.6685074793053091,0.7645451060827053,0.3319338714528529,0.9582822479920875,0.7626300426504634,0.10120386887346844,0.16590750539395605,0.805361728762588,0.43232901232838095,0.16074974066336745,0.20836304633481206,0.11166044458890279,0.5579444153562669,0.711738373513152,0.6493888198004516,0.20209047069445651,0.6332927065424614,0.17808416562533003,0.7193468769055588,0.2219061055062853,0.9332383863588496,0.46534920437732163,0.8699528917765925,0.8714790727235066,0.9332122828043047,0.03722547316125724,0.9714661205599266,0.23097990291096204,0.41254372499114167,0.607235618154869,0.21076453417640784,0.030896211915219296,0.2706681861082395,0.388278121986279,0.900825727834361,0.8248706338056795,0.9599992321205981,0.22769469791692354,0.2861184439154659,0.07601596313172443,0.01242561365512318,0.6244122842176506,0.04701562999448772,0.37883408589757284,0.5331316526209456,0.22442896008478674,0.4850736365055117,0.7503680557562942,0.316988002443787,0.6254971608994644,0.3396918296780601,0.5581751157418005,0.16505471874344047,0.05783463559370583,0.3079490811189368,0.9018394417403922,0.4714389855875044,0.8750845555936055,0.03653168161672071,0.14171122832708294,0.1283315508024857,0.4041343476839492,0.6640649594009365,0.8899458831479509,0.7465321573681416,0.3772305344158289,0.9824776620081301,0.0014112441029455747,0.5012202974638621,0.8884342827822492,0.03310450385492969,0.6967958665309726,0.797926063668395,0.3893276179336831,0.8585843648452202,0.5965689087618445,0.7641842761420913,0.006805536299170911,0.876106049708214,0.769479489486673],\"y\":[0.43772922055923247,0.4991080524446696,0.699407267091977,0.9111924040413424,0.01665151026487255,0.2887448197454503,0.8095320757257898,0.8840792815362104,0.37803614856351864,0.4908974430287081,0.7324621379869188,0.20221053690614887,0.909977469013989,0.4867499074512177,0.7856725492866216,0.519724867865873,0.16596043114280512,0.7214797312683761,0.019551747501428296,0.5390388140082794,0.9600399716837977,0.3385584832009936,0.862147217706044,0.0920031182735862,0.24865496117897723,0.7540699824565609,0.19710188890631475,0.38331200268385635,0.7827795822000765,0.9921753354106315,0.533825567261323,0.0581933166380858,0.7426964070422406,0.026089768638137723,0.8719173009555392,0.7498327613440895,0.10405441940915239,0.6297492653746339,0.7267309166801132,0.7267067774508013,0.5987505609331751,0.5115127632011388,0.15620845885564694,0.7418651241932879,0.43705289658386537,0.851226263746688,0.10897681170022744,0.7819494653370311,0.3875343003103501,0.04955449929009814,0.5015205671752643,0.8614929667844629,0.6143126609787051,0.6519930158846842,0.1516436088130232,0.5096510972821019,0.6800780390147536,0.880407768580314,0.7744277617200289,0.563838632234806,0.05303932957683233,0.2916565578852197,0.5179300842954814,0.19408914684059275,0.23208593200706984,0.871131592187977,0.28785183483978716,0.9770365861897192,0.4259074879093214,0.7753820076363156,0.1286611266468758,0.4021186093941943,0.05816182375455936,0.6634929245315775,0.8267391312929264,0.6216262854439278,0.07225711282108471,0.6516854389163927,0.37765635372618367,0.7556635029193971,0.6818496921195717,0.7494727860898238,0.619245989110435,0.607217096386593,0.6482345655634177,0.15252058897848286,0.5372662739752156,0.16673341652342677,0.18473371806492545,0.23513421837441562,0.5762624615071745,0.3762055648567192,0.4811234709349719,0.7699191821553482,0.3715956579146634,0.043619884501735484,0.6706711508007551,0.26127424420484335,0.44798933500049654,0.15330360388544317],\"z\":[-0.9466417921869978,-0.3964986271574087,-1.1694564560070302,-2.6567958688385676,1.1904272061152075,-0.5124833504947297,-1.5481419700285222,-1.1152325477076335,-0.9881332786149495,-1.3973994234021576,-1.8767096202435043,-0.5004292334352889,-1.0147360572685367,-0.44544521697957706,-1.6756839339600482,-1.1130846818329765,0.3670621023255106,-1.8608613257068736,0.07195995629610788,-1.5177338144412025,-1.5722582056786238,0.556013424850601,-1.9755952448377454,1.7271830541352666,0.8306927099111439,-2.125088820981055,-0.262610094282268,0.5029924220814801,-1.5187257789306372,-2.7381690843798863,-1.217296861206996,0.05408765205862989,-1.1306755895827854,1.4137723015993924,-1.339227111381223,-1.9000915717083189,1.0073459835707965,-1.5782459748481723,-0.7422374002066774,-1.7867881885342847,0.10367387246074111,-0.6084562367311549,1.3426548502783389,-0.4696758322798287,0.6048818144790573,-2.5606279239760927,1.7022507369051412,-1.9389855464317765,-0.3350145084806878,1.1215758503259208,-1.1121082364728627,-2.6057461520098744,-1.335966058206683,-1.2057942930713352,1.4216388411317862,0.15230992941741106,-0.09224353349247982,-2.2511052169734342,-1.7998773291096113,-1.5882662373512775,-0.13832813301242156,0.40713046741288506,-1.5068504383275683,0.19387522517906552,0.4001100812820694,-2.2292071196046765,0.12631394865823453,-1.453040500099912,-0.6546384073869438,-1.0901401857837032,0.3145033497186113,-0.07439994606422129,0.16631325572209094,-1.935375331301108,-1.9161982366583046,-0.0331786572213526,0.7660248199883967,-0.18254729389424584,-1.0940181651560559,-2.044963279563257,-1.8442377888854522,-1.4746835067421604,-0.5251261515003822,-0.013486644187741703,-0.4418096227734978,0.31937029643994375,0.3976776408939049,-0.5139099786064373,0.47988809867284155,1.1367959168820352,-1.7168941725768887,0.297034068659213,0.1841619738052167,-1.569161467020845,0.6510806266395057,1.1175730664444936,-0.47429358758394913,-0.7956585308067554,0.45105576588571017,1.1406657558771394],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"margin\":{\"l\":0,\"r\":0,\"b\":0,\"t\":0},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"x_1\"}},\"yaxis\":{\"title\":{\"text\":\"x_2\"}},\"zaxis\":{\"title\":{\"text\":\"y\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b3c5ecda-77bf-43d9-bad4-d2814327f68b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. inicializar el vector de parametros\n",
        "\n",
        "w_0 = np.random.random(3).reshape(-1,1)*5 #El reshape es para asegurarme que es un vector columna\n",
        "\n",
        "# 3. Construcción de la matriz X\n",
        "\n",
        "N = 3 # filas (caracteristicas + 1)\n",
        "M = len(x_1) # columnas (datos individuales)\n",
        "\n",
        "X = np.zeros((N,M))\n",
        "X[0] = np.ones(M)\n",
        "X[1] = x_1\n",
        "X[2] = x_2\n",
        "\n",
        "# 4. Calculo de la función de coste\n",
        "\n",
        "h = w_0.T @ X             # vector de modelo\n",
        "A = (h - y)          # vector diferencia --> fila\n",
        "J = 0.5/M * np.sum(A**2)   # Función costo evaluada en w_0\n",
        "\n",
        "# 5. Aplicar gradiente descendente\n",
        "\n",
        "w_plus = lambda w , grad_A, alpha: w - alpha*grad_A\n",
        "grad = lambda A,X : X @ A.T\n",
        "model = lambda w,X: w.T @ X\n",
        "coste = lambda A: 0.5/M * np.sum(A**2)\n",
        "\n",
        "def grad_desc(w_0,X,y,alpha,epsilon,tol=5000):\n",
        "\n",
        "  y = y\n",
        "  w = w_0.reshape(-1,1)\n",
        "  cont = 0\n",
        "\n",
        "  A = model(w,X) - y\n",
        "\n",
        "  while np.linalg.norm(grad(A,X)) > epsilon and cont < tol: # se usa la norma pues un\n",
        "    grad_A = grad(A,X)\n",
        "    w = w_plus(w,grad_A,alpha)\n",
        "    A = model(w,X) - y\n",
        "    cont += 1\n",
        "\n",
        "  if cont == tol:\n",
        "    print(\"No converge\")\n",
        "  else:\n",
        "    print(f\"Converged after {cont} iterations.\")\n",
        "\n",
        "  return w.flatten()"
      ],
      "metadata": {
        "id": "EoSJKcW41KeH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. iterar hasta encontrar los parametros del ajuste\n",
        "\n",
        "params = grad_desc(w_0,X,y,0.001,1e-6)\n",
        "print(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uel4--R5Fa_v",
        "outputId": "8e6cfe04-7d47-4df1-d331-437eea61a627"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged after 3226 iterations.\n",
            "[-1.13123114e-07  2.10000009e+00 -3.09999986e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmSzT5PemYbT"
      },
      "source": [
        "7. Reescribir su código como una clase (ver ayuda)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. POO\n",
        "\n",
        "# ¿qué quiero yo? --> generar clase mult. linear regress\n",
        "# Esta será un objeto que recibe una matriz X de features y un vector y de targets\n",
        "# quiero tener un método que me regrese los features que minimizan la fun coste\n",
        "# un método que me permitan ajustar datos nuevos\n",
        "# método que me regrese las iteraciones\n",
        "\n",
        "class MultilinearRegresion():\n",
        "\n",
        "  def __init__(self,X,y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.Nfeatures = X.shape[0]\n",
        "    self.m = X.shape[1]\n",
        "    self.theta = np.random.random(self.Nfeatures).reshape(self.Nfeatures,1)\n",
        "\n",
        "  def model(self):\n",
        "    self.h = self.theta.T @ self.X\n",
        "\n",
        "  def costo(self):\n",
        "    self.A = (self.h - self.y)\n",
        "    self.J = 0.5/self.m * np.sum(self.A**2)\n",
        "\n",
        "  def grad(self):\n",
        "    self.grad_A = self.X @ self.A.T\n",
        "\n",
        "  def update_params(self, learning_rate):\n",
        "    self.theta = self.theta - learning_rate*self.grad_A\n",
        "\n",
        "  def fit(self, learning_rate, epsilon, tol=5000):\n",
        "    \"\"\"\n",
        "    Descenso del gradiente:\n",
        "    learning_rate = alpha\n",
        "    epsilon = tolerancia de solución\n",
        "    tol = número de iteraciones máximas\n",
        "    \"\"\"\n",
        "    cont = 0\n",
        "    self.model()\n",
        "    self.costo()\n",
        "    self.grad()\n",
        "\n",
        "    while np.linalg.norm(self.grad_A) > epsilon and cont < tol:\n",
        "      self.grad()\n",
        "      self.update_params(learning_rate)\n",
        "      self.model()\n",
        "      self.costo()\n",
        "      cont +=1\n",
        "    if cont == tol:\n",
        "      print(\"No converge\")\n",
        "    self.iter = cont\n",
        "\n",
        "  def predict(self,X_new):\n",
        "    return self.theta.T @ X_new\n"
      ],
      "metadata": {
        "id": "bUBbOFhX7Bcn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ajuste = MultilinearRegresion(X,y)\n",
        "ajuste.fit(0.001,1e-6)\n",
        "print(ajuste.theta)\n",
        "print(ajuste.iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMfJ_9g9i8tr",
        "outputId": "87fa9feb-b136-4a0a-eb02-145ec2b77350"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.12581031e-07]\n",
            " [ 2.10000009e+00]\n",
            " [-3.09999987e+00]]\n",
            "3201\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}