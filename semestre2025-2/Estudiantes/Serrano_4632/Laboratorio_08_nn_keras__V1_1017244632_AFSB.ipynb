{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Clasificación del dataset make_moons con Keras\n"
      ],
      "metadata": {
        "id": "K8bknXRUpUyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model_moons = Sequential([\n",
        "    Input(shape=(2,)),\n",
        "    Dense(16, activation=\"relu\", input_shape=(2,)),\n",
        "    Dense(16, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_moons.compile(\n",
        "    optimizer=Adam(learning_rate=0.01),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_moons = model_moons.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "test_loss_moons, test_acc_moons = model_moons.evaluate(X_test, y_test, verbose=0)\n",
        "test_acc_moons\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUXyqhmZobC0",
        "outputId": "a25c47ba-31c7-433c-ed2a-7c21be79dc3b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9649999737739563"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Clasificación del dataset load_digits con Keras\n"
      ],
      "metadata": {
        "id": "pkfsuEQfpvgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "digits = load_digits(n_class=6)\n",
        "X, y = digits.data, digits.target\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)\n",
        "\n",
        "model_digits = Sequential([\n",
        "    Dense(32, activation=\"relu\", input_shape=(n_features,)),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(6, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model_digits.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history_digits = model_digits.fit(\n",
        "    X_train, y_train_cat,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "test_loss_digits, test_acc_digits = model_digits.evaluate(X_test, y_test_cat, verbose=0)\n",
        "test_acc_digits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgD0drn-p1k1",
        "outputId": "50bf211b-5e2d-4d36-ca78-a8bc32e8de7d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.981566846370697"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el dataset make_moons el modelo de red neuronal implementado con Keras alcanzó una exactitud cercana al 96 %, evidenciando su capacidad para modelar fronteras de decisión no lineales. Para el dataset load_digits (6 clases), la red obtuvo una exactitud aproximada del 98 %, mostrando un desempeño sobresaliente en la clasificación multiclase. Estos resultados confirman la eficacia de Keras para entrenar redes neuronales de forma eficiente y estable, en contraste con la implementación manual desarrollada en el laboratorio anterior."
      ],
      "metadata": {
        "id": "7Ro3rtjcqeyW"
      }
    }
  ]
}