{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Salomon Uran Parra C.C. 1015068767**"
      ],
      "metadata": {
        "id": "vTpWmSF3ic9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Laboratorio 8 - Aprendizaje Estadistico**"
      ],
      "metadata": {
        "id": "f0fP7hGwikRe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pav6mG_iiZAu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_moons, make_regression, make_circles, make_blobs, load_digits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Para el dataset make a moon de sklearn, construir un modelo de una red neuronal con keras para clasificar los datos.**"
      ],
      "metadata": {
        "id": "frpi04jJZZVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a crear y visualizar primero el dataset:"
      ],
      "metadata": {
        "id": "oCCjwHrolPht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_moons, y_moons = make_moons(n_samples=1000, noise=0.1, random_state=42) #make_moons permite crear un dataset y clasificarlo para dos figuras en forma de luna\n",
        "\n",
        "print(\"Dimensiones de los datos (X_moons):\", X_moons.shape)\n",
        "print(\"Dimensiones de las etiquetas (y_moons):\", y_moons.shape)\n",
        "print(\"Tipos de datos de las características (X_moons):\", X_moons.dtype)\n",
        "print(\"Valores únicos en las etiquetas (y_moons):\", np.unique(y_moons))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_moons[y_moons == 0, 0], X_moons[y_moons == 0, 1], label='Clase 0', alpha=0.7)\n",
        "plt.scatter(X_moons[y_moons == 1, 0], X_moons[y_moons == 1, 1], label='Clase 1', alpha=0.7)\n",
        "plt.title('Dataset Make Moons')\n",
        "plt.xlabel('Característica 1')\n",
        "plt.ylabel('Característica 2')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fy-22szqZgKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, vamos a crear una red neuronal densa con output Sigmoide que permita clasificar entre la clase 0 (azul) y la clase 1 (naranja) empleando el API Keras de Tensorflow. Definimos el modelo con dos capas ocultas de 4 y 8 neuronas ReLu, similar al modelo de clasificacion de los circulos hecho en el collab de la sesion de Keras. El output sera una funcion sigmoide y se usara una funcion de perdida Binary Cross Entropy:"
      ],
      "metadata": {
        "id": "LITYJR8pnv69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_moons(activation = 'sigmoid', loss='binary_crossentropy'):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Dense(4, input_dim=2, activation='relu'))\n",
        "    model.add(keras.layers.Dense(8, activation='relu'))\n",
        "    model.add(keras.layers.Dense(1, activation = activation))\n",
        "    opt = keras.optimizers.SGD(learning_rate=0.01)\n",
        "    model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "3j1XmDVUeze4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora podemos proceder a entrenar un modelo de clasificacion empleando esta red neuronal. Vamos a disponer del 50% de los datos para entrenamiento y el otro 50% para test, de forma analoga a la clasificacion de los circulos vista en clase. Se entrenaran unicamente 100 epocas, pues el modelo con dos capas ocultas resulta lo suficientemente robusto para lograr una buena precision en pocas epocas de entrenamiento."
      ],
      "metadata": {
        "id": "DjrHtPFCsOUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "n_train = 500 #numero de datos dedicados a entrenamiento de los 1000 datos obtenidos del make_moons\n",
        "\n",
        "train_X, test_X = X_moons[:n_train, :], X_moons[n_train:, :]\n",
        "train_y, test_y = y_moons[:n_train], y_moons[n_train:]\n",
        "#seleccion de conjuntos de entrenamiento y testeo\n",
        "\n",
        "model = build_model_moons()\n",
        "history = model.fit(train_X, train_y, validation_data=(test_X, test_y), epochs=100, verbose=1)\n",
        "#se construye el modelo y el historial de entrenamiento que incluye\n",
        "#la evolucion de la funcion de perdida tanto en el entrenamiento como testeo, y asi mismo la precision en ambos conjuntos\n",
        "\n",
        "_, train_acc = model.evaluate(train_X, train_y, verbose=0)\n",
        "_, test_acc = model.evaluate(test_X, test_y, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "#se imprime tanto la precision en el conjunto de entrenamiento como en el de testeo para cada epoca\n",
        "\n",
        "plt.figure(figsize=(14,7))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nxjtfvUne2uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora por ejemplo, podemos ver como clasifca puntos en el plano. De la imagen original de los datos podemos ver que el punto $(0,1)$ pertenece a la clase 0 mientras que el punto $(1,-0.5)$ pertenece a la clase 1. Veamos que resultado arroja el modelo a la hora de predecir la clase a la que pertenecen:"
      ],
      "metadata": {
        "id": "3kM0jvjNsn3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#clase 0 se clasifica como un numero real menor que 0.5 y mayor que cero, mientras que la clase 1 se clasifica como un real entre 0.5 y 1\n",
        "print(model.predict(np.array([[0,1]])))\n",
        "\n",
        "print(model.predict(np.array([[1,-0.5]])))"
      ],
      "metadata": {
        "id": "39nRmUlPgkxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto vemos que el modelo tiene un buen desempeño a la hora de clasificar puntos que tengan una pertenencia clara a los conjuntos definidos por el dataset. Faltaria analizar la precision que tiene en puntos cercanos a la \"frontera\" que hay entre las dos clases."
      ],
      "metadata": {
        "id": "4T4Zf2A-tQDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Para el dataset load digits, construir un modelo de red neuronal empleando keras para realizar la clasificación.**"
      ],
      "metadata": {
        "id": "w2fCADcaZbgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero visualizaremos el dataset de load_digits, utilizando unicamente los primeros 6 digitos, es decir los enteros del 0 al 5."
      ],
      "metadata": {
        "id": "psjnxnVdvAP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits = load_digits(n_class=6)\n",
        "#se lee el dataset con solo los digitos del 0 a 5\n",
        "\n",
        "X, y = digits.data, digits.target\n",
        "n_samples, n_features = X.shape\n",
        "#se leen los datos y su target o label (la clasificacion de los datos por digitos)\n",
        "\n",
        "fig, axs = plt.subplots(nrows=10, ncols=10, figsize=(6, 6))\n",
        "\n",
        "for idx, ax in enumerate(axs.ravel()):\n",
        "    ax.imshow(X[idx].reshape((8, 8)), cmap=plt.cm.binary)\n",
        "    ax.axis(\"off\")\n",
        "_ = fig.suptitle(\"Algunos de los datos de imagenes en el dataset load_digits\", fontsize=16)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#hacemos un splitting aleatorio de los datos de entrenamiento y test usando train_test_split"
      ],
      "metadata": {
        "id": "-zQje26LZfow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora haremos un modelo de clasificacion similar al del punto anterior pero con las siguientes diferencias: Se emplearan dos capas ocultas de 8 y 16 neuronas ReLu, se usara como output una funcion SoftMax para el multiclasificador y se empleara una funcion de coste que generaliza la binary cross entropy, llamada sparse categorical crossentropy. Nuevamente se hace uso del API Keras."
      ],
      "metadata": {
        "id": "6HzYvsD0wtMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_digits(activation = 'softmax', loss='sparse_categorical_crossentropy'): #clasificacion binaria\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Dense(8, input_dim = 64 , activation='relu'))\n",
        "    model.add(keras.layers.Dense(16, activation='relu'))\n",
        "    model.add(keras.layers.Dense(6, activation = activation))\n",
        "    model.compile( loss=loss, optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "-Oz-S3fPZpuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, como del dataset ya se obtuvo previamente unos conjuntos de entrenamiento y test, simplemente definiremos el modelo utilizando 100 epocas de entrenamiento e imprimiremos nuevamente toda la informacion acerca del entrenamiento como antes."
      ],
      "metadata": {
        "id": "R6w6zqhgxlJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "model = build_model_digits()\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, verbose=1)\n",
        "#se construye el modelo y el historial de entrenamiento nuevamente\n",
        "\n",
        "_, train_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "_, test_acc = model.evaluate(X_train, y_train, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "#se imprime tanto la precision en el conjunto de entrenamiento como en el de testeo para cada epoca\n",
        "\n",
        "plt.figure(figsize=(14,7))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.title('Loss')\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Accuracy')\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ClENZE1AZrKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo se entreno de forma muy eficiente y precisa, logrando una precision de mas del 90% en ambos conjuntos. Podemos visualizar como predice la red neuronal a continuacion, con un ejemplo del digito 5."
      ],
      "metadata": {
        "id": "5Z-M1ouv0mAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X[11].reshape((8, 8)), cmap=plt.cm.binary)"
      ],
      "metadata": {
        "id": "LfBvan4nZuam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prds = model.predict(X)\n",
        "prds[11]"
      ],
      "metadata": {
        "id": "xIqlPuf2Zu03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que el output mas grande esta justamente en el indice 5, es decir, el modelo predice que la imagen \"luce\" como un cinco con la mayor probabilidad."
      ],
      "metadata": {
        "id": "cKG9DCpw02-2"
      }
    }
  ]
}