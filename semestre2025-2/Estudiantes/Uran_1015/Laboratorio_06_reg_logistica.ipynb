{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Salomon Uran Parra C.C. 1015068767**"
      ],
      "metadata": {
        "id": "mOptqLhI0A-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Laboratorio 6 - Aprendizaje Estadistico**"
      ],
      "metadata": {
        "id": "hW-QpDnL0GfR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PufoZgiRz5JU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se deja como tarea motrar que:\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}-h_\\theta X^{(i)}] X_j^{(i)}\n",
        "\\end{equation}\n",
        "\n",
        "Para la demostración, muestre que:\n",
        "- $f(z)=\\frac{1}{1+e^{-z}} = f(z)(1-f(z))$\n",
        "- $\\frac{\\partial h_{\\theta}}{\\partial \\theta_j } = h_{\\theta}(X^{(i)})(1-h_{\\theta}(X^{(i)}))X_j^{(i)}$"
      ],
      "metadata": {
        "id": "riKjnkPvWRIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero, tengamos presente que:\n",
        "\n",
        "$$1 - f(z) = 1 - \\frac{1}{1+e^{-z}} = \\frac{1-1+e^{-z}}{1+e^{-z}} = \\frac{e^{-z}}{1+e^{-z}}$$\n",
        "\n",
        "Asi, podemos realizar la derivada:\n",
        "\n",
        "$$f'(z) = - \\frac{1}{(1+e^{-z})^2} (-e^{-z}) = \\frac{1}{1+e^{-z}} \\frac{e^{-z}}{1+e^{-z}} = f(z)(1-f(z))$$\n",
        "\n",
        "\n",
        "Ahora, tengamos en cuenta que $h_\\theta(X^{(i)}) = \\frac{1}{1+e^{\\Theta^T X^{(i)}}}$, y realizemos la derivada:\n",
        "\n",
        "\n",
        "$$\\frac{\\partial h_\\theta (X)}{\\partial \\theta_j} = - \\frac{1}{(1+e^{\\Theta^T X})^2}(e^{\\Theta^T X})\\frac{\\partial (\\Theta^T X)}{\\partial \\theta_j} = - h_\\theta (X)(1-h_\\theta(X)) X_j$$\n",
        "\n",
        "\n",
        "Asi, podemos derivar la expresion completa de $ J (\\Theta) =\\frac{1}{m} \\sum_{i=1}^{m} \\left[-y^{(i)}\\log (h_{\\theta}(X ^ {i})) - (1-y^{(i)})\\log (1-h_{\\theta}(X^{i})) \\right]$:\n",
        "\n",
        "\n",
        "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum^{m}_{i = 1} [-y^{(i)} \\frac{\\partial}{\\partial \\theta_j} log(h_\\theta(X^{(i)})) - (1-y^{(i)}) \\frac{\\partial}{\\partial \\theta_j} log(1-h_\\theta(X^{(i)}))]$$\n",
        "\n",
        "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum^{m}_{i = 1} [-y^{(i)} \\frac{1}{h_\\theta(X^{(i)})}\\frac{\\partial h_\\theta}{\\partial \\theta_j} + (1-y^{(i)})  \\frac{1}{1-h_\\theta(X^{(i)})} \\frac{\\partial h_\\theta}{\\partial \\theta_j}]$$\n",
        "\n",
        "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum^{m}_{i = 1} [-y^{(i)} \\frac{1}{h_\\theta(X^{(i)})} (- h_\\theta (X^{(i)})(1-h_\\theta(X^{(i)})) X^{(i)}_j) + (1-y^{(i)})  \\frac{1}{1-h_\\theta(X^{(i)})} (- h_\\theta (X^{(i)})(1-h_\\theta(X^{(i)})) X^{(i)}_j)]$$\n",
        "\n",
        "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum^{m}_{i = 1} [y^{(i)} (1-h_\\theta(X^{(i)})) X^{(i)}_j - (1-y^{(i)})  h_\\theta (X^{(i)}) X^{(i)}_j]$$\n",
        "\n",
        "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum^{m}_{i = 1} [y^{(i)} - h_\\theta (X^{(i)})] X^{(i)}_j$$\n"
      ],
      "metadata": {
        "id": "kOgEZWWeWZ-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tomar el [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) desde sklearn:\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "```\n",
        "- Realizar la clasifición de las tres clases  a traves de una regresión logística  y realizar multiclasicación, para ello considere lo siguiente:\n",
        "\n",
        "Si en un dataset existen más de 2 clases, $y={0, 1, 2, 3, ...}$ se debe construir una multiclasificación, una contra todos, la estrategia sugerida es la siguiente.\n",
        "\n",
        "Sea A, B, C las tres clases. Para estos valores definir:\n",
        "\n",
        "1. Definir la clase A como la clase 0 y todas las otras B, C como la clase 1\n",
        "2. Encontrar el valor $h_\\theta(X) = P(y=A|x;\\theta)$\n",
        "3. Definir la clase B como la clase 0 y todas las otras A, C como la clase 1\n",
        "4. Encontrar el valor $h_\\theta(X) = P(y=B|x;\\theta)$\n",
        "5. Definir la clase C como la clase 0 y todas las otras A, B como la clase 1\n",
        "6. Encontrar el valor $h_\\theta(X) = P(y=C|x;\\theta)$\n",
        "\n",
        "\n",
        "Estrategia de solución."
      ],
      "metadata": {
        "id": "SI3_Cqoy0Oo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Para tener una vision general de los datos analiza lo que contiene la clave DESCR del dataset**\n",
        "```\n",
        "print(iris.DESCR)\n",
        "```"
      ],
      "metadata": {
        "id": "ClopGfMw0ega"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "print(iris.DESCR)"
      ],
      "metadata": {
        "id": "Rz3Udi6M0gl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset contiene medidas de 150 plantas de 3 especies distintas, con 50 registros de datos para cada especie. La clase 0 en el dataset es la especie Setosa, la clase 1 es la Versicolour, y la 2 es la Virginica. Para cada flor se hallan 4 atributos numericos, sepal length, sepal width, petal length and petal width (todo en cm). A lo ultimo se menciona, que una de las clases es linealmente separable de las otras dos, mientras que las ultimas no lo son."
      ],
      "metadata": {
        "id": "NH_zsIFBc2t-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Construye un dataframe:**\n",
        "- los datos se pueden encontrar con la clave \"data\".\n",
        "- los nombres de las caracteristicas con la clave: \"names_features\"\n",
        "- La clave target nos permite indentificar el tipo de datos.\n"
      ],
      "metadata": {
        "id": "M5U6G6g40hBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df[\"Target\"] = iris.target\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ltCCxAoa0lkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Cambia el nombre de las columnas del dataframe, empleando intrucción como:**\n",
        "```\n",
        "columns_name =[ \"\".join([c.capitalize() for c in cols.split()])  for cols in df.columns ]\n",
        "columns_name =[col.replace(\"(\" ,\"_\") for col in columns_name ]\n",
        "cols = [col.replace(\")\" ,\"\") for col in columns_name ]\n",
        "```\n"
      ],
      "metadata": {
        "id": "eHQveqsf0l_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_name =[ \"\".join([c.capitalize() for c in cols.split()])  for cols in df.columns ]\n",
        "columns_name =[col.replace(\"(\" ,\"_\") for col in columns_name ]\n",
        "cols = [col.replace(\")\" ,\"\") for col in columns_name ]\n",
        "df.columns = cols\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gf0_qBCR0qzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Analizar el dataframe, numeros de datos, cantidad de null, descripción del dataframe.**"
      ],
      "metadata": {
        "id": "42H6yD1V0rLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "O-kL2ukh0uYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby([\"Target\"])[\"SepalLength_cm\"].describe()"
      ],
      "metadata": {
        "id": "OVG_dQ6Je47c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Aplica estadística básica y construye graficas para entender el dataset. Encuentra la matriz de correlacion**"
      ],
      "metadata": {
        "id": "vvfBQi_70uxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vamos a hacer graficas de dispersion entre los datos para entender como estan de correlacionados entre si\n",
        "#vamos a distinguir entre las diferentes especies de planta\n",
        "\n",
        "sns.pairplot(df, hue = \"Target\", palette = \"viridis\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8vt5ZqjEhD7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Encontrar la matrix de correlacion, emplear el metodo corr(), dentro de seaborn buscar el metodo heatmap() para realizar un grafico de la matrix de correlación.**"
      ],
      "metadata": {
        "id": "7He6x0ne0y4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix = df.corr()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Matriz de correlacion del dataset Iris')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l45RrksL0112"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. Separar los datos en datos de entramiento y test, prueba la siguiente instruccion:**\n",
        "```\n",
        "split = StratifiedShuffleSplit(n_splits = 1, test_size=0.2, random_state=42)\n",
        "\n",
        "for train_index, test_index in split.split(df, df[\"Target\"]):\n",
        "  strat_train_set = df.loc[train_index]\n",
        "  strat_test_set = df.loc[test_index]\n",
        "```\n",
        "¿Cómo se estan seprando los datos?"
      ],
      "metadata": {
        "id": "t2hh4sSt02UG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente codigo emplea un remuestreo estratificado por medio de la columna Target, para mantener la proporcion de plantas en los conjuntos de entrenamiento y testeo que se obtendran."
      ],
      "metadata": {
        "id": "hPO3c116icOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split = StratifiedShuffleSplit(n_splits = 1, test_size=0.2, random_state=42)\n",
        "#se define la funcion de remuestreo estratificado\n",
        "\n",
        "for train_index, test_index in split.split(df, df[\"Target\"]):\n",
        "  train = df.loc[train_index]\n",
        "  test= df.loc[test_index]\n",
        "\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "#imprimamos las proporciones del target para cada uno\n",
        "print(df[\"Target\"].value_counts() / len(df))\n",
        "\n",
        "print(train[\"Target\"].value_counts() / len(train))\n",
        "\n",
        "print(test[\"Target\"].value_counts() / len(test))"
      ],
      "metadata": {
        "id": "foilvnGW07Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8. Construye un modelo empleando una regresión logística, para clasificar la clase setosa y no setosa, emplea la libreria sklearn.**"
      ],
      "metadata": {
        "id": "gK4PYvb107hk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para mantenerlo sencillo y facil de graficar, vamos a emplear un unico feature para clasificar la especie. Como se puede ver en el pairplot, sobre todo las graficas de la densidad de distribucion del histograma de cada feature, el petal_length y petal_width separan bastante bien la especie Setosa de las otras dos. Vamos a escoger petal_length para realizar el modelo de clasificacion."
      ],
      "metadata": {
        "id": "4U8-NwcNm9AT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7b18bff"
      },
      "source": [
        "#se definen el feature y el label o target para el entrenamiento\n",
        "X_binary_train = train[['PetalLength_cm']].values\n",
        "y_binary_train = train[\"Target\"].values\n",
        "\n",
        "#aqui definimos toda especie o target que no sea setosa como 1, mientras que la setosa es 0 desde el inicio\n",
        "y_binary_train[y_binary_train > 0] = 1\n",
        "\n",
        "#se entrena el modelo usando sklearn\n",
        "log_reg_binary_train = LogisticRegression(solver=\"lbfgs\")\n",
        "log_reg_binary_train.fit(X_binary_train, y_binary_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9. Determine  la frontera de clasificación:**\n",
        "```\n",
        "X_new = np.linspace(-10, 10, 1000).reshape(-1, 1)#Generamos los valores de X_new\n",
        "prob = log_reg.predict_proba(X_new)\n",
        "\n",
        "decision_boundary = X_new[prob[:, 0] >= 0.5][0]\n",
        "decision_boundary\n",
        "```"
      ],
      "metadata": {
        "id": "wCh1HyrA0-_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, como ya tenemos un clasificador que toma valores de petal_length  (normalizados) y lanza una prediccion acerca de si es o no es una planta Setosa, podemos hacer un sample uniforme de posibles valores para petal_length y ver desde que momento el modelo empieza a clasificarlo como setosa o como no setosa. Recordemos que en el histograma de petal_length, los valores mas pequeños correspondian a la Setosa, por lo que esperamos que si empiezo el sample desde numeros negativos, deberia esperar que la prediccion empiece en 1 (Setosa para estos valores), y debo buscar justo el punto donde la prediccion se vuelve menor que 0.5 (osea lo clasifica como no setosa)."
      ],
      "metadata": {
        "id": "zEPdqXtDoWif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hago el sample uniforme entre -3 y 3\n",
        "X_new = np.linspace(-2, 8, 1000).reshape(-1, 1)\n",
        "\n",
        "#hago las predicciones para cada uno de los valores\n",
        "prob = log_reg_binary_train.predict_proba(X_new)\n",
        "\n",
        "#tomo el primer valor que el modelo clasifica como no setosa\n",
        "decision_boundary = X_new[prob[:, 0] <= 0.5][0]\n",
        "decision_boundary"
      ],
      "metadata": {
        "id": "L4jh-XC11DkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **10. Encontrar una gráfica de la regresión logística  con los valores de probabilidad**\n"
      ],
      "metadata": {
        "id": "ELtacZEg1EtS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c12f50b"
      },
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "plt.scatter(X_binary_train, y_binary_train, c=y_binary_train, cmap='coolwarm', zorder=20, label = \"Datos entrenamiento\")\n",
        "#primero graficamos los datos\n",
        "\n",
        "plt.plot(X_new, prob[:, 1], \"g-\", label=\"Probabilidad No Setosa\")\n",
        "#ahora graficamos la probabilidad asociada a la prediccion no setosa\n",
        "\n",
        "plt.plot(X_new, prob[:, 0], \"r-\", label=\"Probabilidad Setosa\")\n",
        "#igual para la probabilidad de setosa\n",
        "\n",
        "plt.axvline(decision_boundary[0], color='black', linestyle='--', label='Frontera')\n",
        "#graficamos la frontera de decision\n",
        "\n",
        "plt.xlabel(\"Petal Length\")\n",
        "plt.ylabel(\"Probabilidad\")\n",
        "plt.title(\"Modelo de clasificacion para las plantas Setosa\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **11. Construye el multiclasificador. Puede emplear los metodos dentro de logistic regresión.**"
      ],
      "metadata": {
        "id": "OvJD7clS1H9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora podemos emplear todos los features disponibles en el dataframe para entrenar no solo un clasificador de Setosa, si no un clasificador para las tres especies, es decir, que sea capaz de discernir cuando una entrada corresponde a Setosa, Virginica o Versicolour."
      ],
      "metadata": {
        "id": "KI5InOjbrPQ9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e84c7f44"
      },
      "source": [
        "#se definen los features y el label o target\n",
        "features = ['SepalLength_cm', 'SepalWidth_cm', 'PetalLength_cm', 'PetalWidth_cm']\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits = 1, test_size=0.20, random_state=10)\n",
        "#se define la funcion de remuestreo estratificado\n",
        "\n",
        "for train_index, test_index in split.split(df, df[\"Target\"]):\n",
        "  train = df.loc[train_index]\n",
        "  test= df.loc[test_index]\n",
        "\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "X_multi = train[features].values\n",
        "y_multi = train[\"Target\"].values\n",
        "\n",
        "#se crea el modelo de multiclasificador\n",
        "log_reg_multi = LogisticRegression()\n",
        "\n",
        "#se entrena el modelo con los datos\n",
        "log_reg_multi.fit(X_multi, y_multi)\n",
        "\n",
        "#imprimamos el score\n",
        "log_reg_multi.score(test[features].values, test[\"Target\"].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es importante tener en cuenta que el score en este caso es susceptible a la semilla de aleatoriedad que se use en el shuffle stratificado, pues para diferentes semillas, al ser poquitos datos, los remuestreos pueden diferir bastante."
      ],
      "metadata": {
        "id": "mZKAY9Z83gVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **12. Dado X = [4.9,5.0, 1.8, 0.3] asociados a todas las caracteristicas, ¿cuál es la probabilidad de que la flor sea setosa, versicolor o virginica?**"
      ],
      "metadata": {
        "id": "7YqNBj611LZU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bee5f051"
      },
      "source": [
        "#SepalLength=4.9, SepalWidth=5.0, PetalLength=1.8, PetalWidth=0.3\n",
        "X_new_sample = np.array([[4.9, 5.0, 1.8, 0.3]])\n",
        "\n",
        "#se obtienen las probabilidades asociadas a cada especie\n",
        "probabilities = log_reg_multi.predict_proba(X_new_sample)\n",
        "\n",
        "print(\"Probabilidad para las caracteristicas dadas:\")\n",
        "print(f\"Setosa (Clase 0): {probabilities[0][0]:.4f}\")\n",
        "print(f\"Versicolor (Clase 1): {probabilities[0][1]:.4f}\")\n",
        "print(f\"Virginica (Clase 2): {probabilities[0][2]:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asi, es casi seguro que los datos X estan asociados a una especie Setosa."
      ],
      "metadata": {
        "id": "yVn9nAWE3t5a"
      }
    }
  ]
}