{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Salomon Uran Parra C.C. 1015068767**"
      ],
      "metadata": {
        "id": "3MW_c78swAKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Laboratorio 3 - Aprendizaje Estadistico**"
      ],
      "metadata": {
        "id": "KZxKXFuRwOf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pandas as pd\n",
        "import sympy as sym\n",
        "from sympy import symbols, sin, cos, exp, diff"
      ],
      "metadata": {
        "id": "hKN9jw-nxKZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Supongamos que un conjunto de características y datos etiquetados estan dados de la siguiente manera:**\n",
        "\n",
        "Crear un data frame de pandas con los siguientes datos:\n",
        "\n",
        "|Entrenamiento|Y| X_1 |\n",
        "|-|-|-|\n",
        "|0|0|0|\n",
        "|1|1|1|\n",
        "|2|2|2|\n",
        "|3|3|3|\n",
        "|4|4|4|\n",
        "|m|5|5|\n"
      ],
      "metadata": {
        "id": "XJlZzrhnwEVT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Prlj3xMvnqY"
      },
      "outputs": [],
      "source": [
        "#definir los dataframe\n",
        "\n",
        "Y = [0,1,2,3,4,5]\n",
        "X_1 = [0,1,2,3,4,5]\n",
        "\n",
        "dic = {'X_1' : X_1, 'Y' : Y}\n",
        "\n",
        "df = pd.DataFrame(dic)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Crear una función para calcular la función de coste.**"
      ],
      "metadata": {
        "id": "9PssbwQuwayE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h = lambda theta0,theta1,X: theta0 + theta1*X\n",
        "#modelo lineal propuesto, empleando los datos del df\n",
        "\n",
        "m = df.shape[0]\n",
        "#dimension de los datos\n",
        "\n",
        "coste = lambda theta0,theta1: (1/(2*m))*sum( [ (h(theta0,theta1,df['X_1'][i])-df['Y'][i])**2 for i in range(m) ] )\n",
        "#funcion de coste con metrica euclidiana para los datos en el dataframe df"
      ],
      "metadata": {
        "id": "YzVfsqT8wb0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Asumiendo que $\\theta_0=0$, represente gráficamente la función de costo para diferentes valores de $\\theta_1$. Determine el valor mínimo de la función de costo y, con este valor, grafique la ecuación de regresión obtenida sobre los datos del dataframe que ha construido.**"
      ],
      "metadata": {
        "id": "EnPXKqehwcRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theta0 = 0\n",
        "#valor fijo de theta0\n",
        "\n",
        "theta1 = np.linspace(-3,5,1000)\n",
        "#theta1 variable\n",
        "\n",
        "plt.plot(theta1, coste(theta0,theta1), label = r'$J( \\theta_1)$')\n",
        "plt.title('Funcion de coste')\n",
        "plt.xlabel('$\\\\theta_1$')\n",
        "plt.ylabel('Coste')\n",
        "plt.legend()\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "fU5bBzQowfHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De aquí se puede observar que el valor mínimo de la función de coste ocurre en un valor cercano de $\\theta_1 = 1$, luego, grafiquemos como quedaría el modelo lineal con este valor y $\\theta_0 = 0$:"
      ],
      "metadata": {
        "id": "5sSn079mzMMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theta1 = 1\n",
        "plt.scatter(df['X_1'],df['Y'],label = 'Datos', s=70)\n",
        "plt.plot(df['X_1'], h(theta0,theta1,df['X_1']), label = r'$h(x) = \\theta_0 + \\theta_1 x$', color = 'orange')\n",
        "plt.title('Modelo lineal')\n",
        "plt.xlabel('X_1')\n",
        "plt.ylabel('Y')\n",
        "plt.legend()\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "Z1KlcKc8zMrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Suponiendo ahora que los datos de entrenamiento viene dados de la siguiente manera:**\n",
        "\n",
        "|Entrenamiento|Y| X_1 |\n",
        "|-|-|-|\n",
        "|0|0|0|\n",
        "|1|1|1|\n",
        "|2|2|2|\n",
        "|3|3|3|\n",
        "|4|4|4|\n",
        "|m|5|5|\n",
        "\n",
        "Encontrar la función de coste para diferentes valores de $\\theta_0$, $\\theta_1$.\n",
        "Para ello puede emplear los metodos `surface` y `contour` dentro de la libreria de `matplotlib`.  Construya primero, con los valores de $\\theta_0$, $\\theta_1 $ definidos un `np.meshgrid` y evalue  para cada punto $\\theta_0$, $\\theta_1$ la función de coste.\n",
        "\n",
        "Para el gráfico 3D puede emplear algo similar a las siguientes lineas de código\n",
        "\n",
        "```\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot_surface(t0, t1, J )\n",
        "ax.contour(t0, t1, J, 200,   linestyles=\"solid\")\n",
        "ax.set_xlabel(\"$\\\\theta_0$\")\n",
        "ax.set_ylabel(\"$\\\\theta_1$\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "\n",
        "En los casos anteriores la solución solo involucra 1 y 2 parámetros para la representación de la función de coste en  2D y 3D respectivamente. Cuando se tienen más parametros a optmizar, no podemos tener una representacion gráfica, análoga a los casos anteriores. Notese además que los datos anteriores no tiene ningún ruido y solo se esta realizados  de esta manera, por motivos didácticos."
      ],
      "metadata": {
        "id": "o_kSiGAgwfhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theta0 = np.linspace(-0.1,0.1,1000)\n",
        "theta1 = np.linspace(0.9,1.1,1000)\n",
        "#hago puntos para theta0 y theta1\n",
        "\n",
        "t0,t1 = np.meshgrid(theta0,theta1)\n",
        "#hago la malla para evaluar la funcion\n",
        "\n",
        "J = coste(t0,t1)\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(12, 6))\n",
        "\n",
        "cont = ax[0].contourf(t0, t1, np.log(J), 20, cmap = 'YlGn')\n",
        "ax[0].set_xlabel(\"$\\\\theta_0$\")\n",
        "ax[0].set_ylabel(\"$\\\\theta_1$\")\n",
        "ax[0].set_title(\"Grafica de contorno de la funcion de costo J\")\n",
        "\n",
        "ax[1] = fig.add_subplot(1, 2, 2, projection='3d')\n",
        "surf = ax[1].plot_surface(t0, t1, J, cmap='viridis')\n",
        "ax[1].set_xlabel(\"$\\\\theta_0$\")\n",
        "ax[1].set_ylabel(\"$\\\\theta_1$\")\n",
        "ax[1].set_zlabel(\"Cost\")\n",
        "ax[1].set_title(\"GRafica de superficie de la funcion de costo J\")\n",
        "\n",
        "\n",
        "fig.colorbar(cont, ax=ax[0])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IdQTmYTHwlJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Encontrar la expresión teórica para la función de coste en el caso 1D y 2D.**"
      ],
      "metadata": {
        "id": "glx9lmdjwnbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función de coste para un modelo $h_{\\theta}(x_j)$ con un conjunto de parámetros $\\theta$ y una cantidad de features $x_j$, usando la métrica euclídea es:\n",
        "\n",
        "$$J = \\frac{1}{2m} \\sum_{i=0}^m ( h_{\\theta} (x^{(i)}_j)-y^{(i)})^2$$\n",
        "\n",
        "Donde $m$ es el número de datos de cada una de las características, $x^{(i)},y^{(i)}$ son el $i$-esimo dato de la característica y su label o valor esperando, respectivamente.\n",
        "\n",
        "En el caso del modelo lineal en 1D, $h(x) = \\theta_0 + \\theta_1 x$, luego:\n",
        "\n",
        "$$J = \\frac{1}{2m} \\sum_{i=0}^m ( \\theta_0 + \\theta_1 x^{(i)} - y^{(i)})^2$$\n",
        "\n",
        "Expandiendo, se llega a lo siguiente:\n",
        "\n",
        "$$J = \\frac{1}{2m} \\sum_{i=0}^m (\\theta_0^2 + \\theta_1^2 x^{(i)2} + y^{(i)2} + 2\\theta_0 \\theta_1 x^{(i)} - 2\\theta_0 y^{(i)} - 2\\theta_1 x^{(i)} y^{(i)})$$\n",
        "\n",
        "Que representa un paraboloide en el espacio de las variables $\\theta_0 , \\theta_1$, el cual debe anularse para un valor optimo de dichas variables.\n",
        "\n",
        "En el caso 2D, el cálculo es similar. El modelo supuesto es de la forma $h(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2$, luego:\n",
        "\n",
        "$$J = \\frac{1}{2m} \\sum_{i=0}^m ( \\theta_0 + \\theta_1 x_1^{(i)} + \\theta_2 x_2^{(i)} - y^{(i)})^2$$\n",
        "\n",
        "Expandiendo, se llega a lo siguiente:\n",
        "\n",
        "$$J = \\frac{1}{2m} \\sum_{i=0}^m (\\theta_0^2 + \\theta_1^2 x_1^{(i)2} + \\theta_2^2 x_2^{(i)2} + y^{(i)2} + 2\\theta_0 \\theta_1 x_1^{(i)} + 2\\theta_0 \\theta_2 x_2^{(i)} - 2\\theta_0 y^{(i)} + 2\\theta_1 \\theta_2 x_1^{(i)}x_2^{(i)} - 2\\theta_1 x_1^{(i)} y^{(i)} - 2\\theta_2 x_2^{(i)} y^{(i)})$$\n",
        "\n",
        "Que nuevamente representa un paraboloide en el espacio de los parámetros $\\theta_0, \\theta_1, \\theta_2$ que se debe anular con valores óptimos de las variables.\n"
      ],
      "metadata": {
        "id": "zuWUV1XgzRhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. Construya un algoritmo en el que emplee el gradiente descente para determinar el minimo de una función, determine el mínimo con una error epsilon de  1E-4, pruebe su algoritmo para $f(x)= (x-4)^2$ y al menos 3 valores de $\\alpha$**"
      ],
      "metadata": {
        "id": "EMFS3tTawqaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GD(wi, function, dfunc, alpha, eps = 1e-4): #toma el punto inicial, la funcion, su derivada, el learning parameter alpha y el epsilon\n",
        "\n",
        " while function(wi) > eps:\n",
        "\n",
        "  wi = wi - alpha*dfunc(wi)\n",
        "  #algoritmo de gradiente descendente\n",
        "\n",
        " return wi\n",
        "\n",
        "alpha = [0.5,0.4,0.1]\n",
        "#tres valores distintos de alpha\n",
        "\n",
        "func = lambda x: (x-4)**2\n",
        "dfunc = lambda x: 2*(x-4)\n",
        "#funcion y su derivada\n",
        "\n",
        "wi = 2\n",
        "#punto inicial desde donde empieza el gradiente descendente\n",
        "\n",
        "for i in alpha:\n",
        "\n",
        "  print('alpha: ', i, ', minimo:',GD(wi,func,dfunc,i))\n",
        "  #valores del minimo de la funcion, que debe ser 4 exactamente\n",
        "\n",
        "#dcoste = lambda theta0, theta1: (1/m)*sum( [ (np.abs((theta0+theta1*X_1[i] - Y[i]))*X_1[i]) for i in range(len(X_1)) ] )"
      ],
      "metadata": {
        "id": "xNt0k3f4wvsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. Para responder este punto puede consultar la siguiente  página y seguir el video[Ejemplo guia: dotcsv](https://www.youtube.com/watch?v=-_A_AAxqzCg):**\n",
        "\n",
        "Encontrar el mínimo de la siguiente función a través del metodo del gradiente descendente https://en.wikipedia.org/wiki/Gradient_descent:\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "F(x,y) = \\sin \\left( \\frac{1}{2}x^2-\\frac{1}{4}y^2 +3\\right) \\cos (2x+1-e^y)\n",
        "\\end{equation}\n",
        "\n",
        "  -  Para ello realice una gráfica de la función en 3D, y un mapa de contorno de la función.\n",
        "  - Determine el valor mínimo de la función con el metodo del gradiente descendente."
      ],
      "metadata": {
        "id": "aJbqX2vCwwQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#se definen las variables simbolicas x,y\n",
        "x, y = symbols('x y')\n",
        "\n",
        "#y se definel a funcion F(x,y)\n",
        "F = sin((1/2)*x**2 - (1/4)*y**2 + 3) * cos(2*x + 1 - exp(y))\n",
        "\n",
        "#se calculan las derivadas parciales de F para construir el gradiente\n",
        "dFx = diff(F, x)\n",
        "dFy = diff(F, y)\n",
        "\n",
        "#se convierten las funciones simbolicas en funciones que permiten ser evaluadas en arrays\n",
        "f = sym.lambdify((x, y), F, 'numpy')\n",
        "dfx = sym.lambdify((x, y), dFx, 'numpy')\n",
        "dfy = sym.lambdify((x, y), dFy, 'numpy')\n",
        "\n",
        "#se crean puntos en x e y para evaluar la funcion\n",
        "x = np.linspace(-3, 3, 100)\n",
        "y = np.linspace(-3, 3, 100)\n",
        "\n",
        "#se evalua la funcion\n",
        "X, Y = np.meshgrid(x, y)\n",
        "Z = f(X, Y)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 7))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_zlabel('F(x, y)')\n",
        "ax.set_title('Grafico de superficie de F(x, y)')\n",
        "ax.view_init(elev=80, azim=55)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "942TQ6PFzjhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GD_2d(func, dfuncx, dfuncy, wi, alpha, eps = 1e-4): #toma la funcion y sus derivadas parciales, adicional un punto inicial como lista, un learning rate y un numero de iteraciones\n",
        "    p0 = np.array(wi)\n",
        "    trayecto = [p0] #se añade el punto inicial al trayecto\n",
        "\n",
        "    while func(p0[0],p0[1]) > eps:\n",
        "        grad_x = dfuncx(p0[0], p0[1])\n",
        "        grad_y = dfuncy(p0[0], p0[1])\n",
        "        gradiente = np.array([grad_x, grad_y])\n",
        "\n",
        "        p0 = p0 - alpha * gradiente #gradiente descendente\n",
        "        trayecto.append(p0) #siguiente punto del trayecto\n",
        "\n",
        "    return p0, np.array(trayecto)\n",
        "\n",
        "\n",
        "inicio = [-2, -1]\n",
        "alpha = 0.01\n",
        "#parametros del GD\n",
        "\n",
        "minimo, trayecto = GD_2d(f, dfx, dfy, inicio, alpha)\n",
        "#se ejecuta el algoritmo\n",
        "\n",
        "print(\"Se encontro el minimo:\", minimo, 'para la funcion F(x,y) desde el punto inicial', inicio)\n",
        "print(\"El valor de la funcion en este minimo es:\", f(minimo[0], minimo[1]))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "contour = plt.contourf(X, Y, Z, 50, cmap='viridis') #se plotea el contorno\n",
        "plt.colorbar(contour)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Grafico de contorno de la funcion F(x,y)')\n",
        "\n",
        "\n",
        "tx = trayecto[:, 0]\n",
        "ty = trayecto[:, 1]\n",
        "plt.plot(tx, ty, marker='o', color='red', markersize=4, linestyle='-',label = 'Trayectoria')\n",
        "plt.scatter(tx[0], ty[0], color='green', s=100, label='Inicio')\n",
        "plt.scatter(tx[-1], ty[-1], color='blue', s=100, label='Fin')\n",
        "#se plotea la trayectoria diferenciando el inicio y final\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oorr8KSlw0Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8. Empleando los siguientes datos :**\n",
        "\n",
        "```\n",
        "X = np.linspace(0, 1, 100)\n",
        "y = 0.2 + 0.2*X + 0.02*np.random.random(100)\n",
        "```\n",
        "\n",
        "y las herramientas desarrolladas en los apartados anteriores,\n",
        "construya un algorítmo que permita determinar una regresión lineal."
      ],
      "metadata": {
        "id": "CcJX-3Jww1_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defino los datos\n",
        "X = np.linspace(0, 1, 100)\n",
        "y = 0.2 + 0.2*X + 0.02*np.random.random(100)\n",
        "\n",
        "#para un modelo lineal, como se definio arriba, la funcion de costo usando la metrica euclidiana y teniendo como argumentos los datos x,y y theta0, theta1 es\n",
        "def costo(x, y, theta0, theta1):\n",
        "    m = len(y)\n",
        "    cost = (1 / (2 * m)) * np.sum((theta0 + theta1 * x - y)**2)\n",
        "    return cost\n",
        "\n",
        "#ahora como necesitamos ajustar theta0 y theta1 necesitamos las derivadas parciales con respecto a estos valores de la funcion de costo\n",
        "def grad(x, y, theta0, theta1):\n",
        "    m = len(y)\n",
        "    g0 = (1 / m) * np.sum(theta0 + theta1 * X - y)\n",
        "    g1 = (1 / m) * np.sum((theta0 + theta1 * X - y) * X)\n",
        "    return g0, g1 #retorna ambas derivadas parciales evaluadas en el valor actual de theta0 y theta1\n",
        "\n",
        "#definimos el gradiente descendente\n",
        "def GDlineal(x, y, theta0, theta1, alpha, n):\n",
        "\n",
        "    historial_costo = [] #lista para guardar el costo en cada iteracion\n",
        "\n",
        "    for i in range(n):\n",
        "\n",
        "        grad0, grad1 = grad(x, y, theta0, theta1)\n",
        "        theta0 = theta0 - alpha * grad0\n",
        "        theta1 = theta1 - alpha * grad1\n",
        "        #algoritmo de gradiente descendente\n",
        "\n",
        "        c = costo(x, y, theta0, theta1)\n",
        "        historial_costo.append(c) #grafica de la funcion de costo\n",
        "\n",
        "    return theta0, theta1, historial_costo\n",
        "\n",
        "\n",
        "theta0, theta1 = np.random.random(2)\n",
        "alpha = 0.1\n",
        "\n",
        "rl_theta0, rl_theta1, historial_costo = GDlineal(X, y, theta0, theta1, alpha,1000)\n",
        "\n",
        "print(f\"Valor de theta0: {rl_theta0}\")\n",
        "print(f\"Valor de theta1: {rl_theta1}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(X, y, label='Datos', s=20) #datos\n",
        "plt.plot(X, rl_theta0 + rl_theta1 * X, color='red', label='Modelo lineal fitteado') #modelo\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Regresion lineal usando gradiente descendente')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(np.log(historial_costo)) #funcion de costo vs numero de iteraciones\n",
        "plt.xlabel('Numero de iteraciones')\n",
        "plt.ylabel('log(costo)')\n",
        "plt.title('Evolucion de la funcion de costo')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TWXZDFKew_pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9. Compare su resultado empleando la libreria linearRegresion() de sklearn.**"
      ],
      "metadata": {
        "id": "JqzY5C3jw_40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#se hace reshape del array X para que sea una matriz mx1\n",
        "Xn = X.reshape(-1, 1)\n",
        "\n",
        "#se crea un modelo de regresion lineal con scikit\n",
        "model = LinearRegression()\n",
        "\n",
        "#se entrena el modelo con los datos X y los labels Y\n",
        "model.fit(Xn, y)\n",
        "\n",
        "#se extraen los parametros de la regresion\n",
        "sklearn_theta0 = model.intercept_\n",
        "sklearn_theta1 = model.coef_[0]\n",
        "\n",
        "print(f\"Theta0 usando scikit learn: {sklearn_theta0}\")\n",
        "print(f\"Theta1 usando scikit learn: {sklearn_theta1}\")\n",
        "\n",
        "print(f\"La diferencia entre scikit y el codigo propio en el theta0 es: {abs(rl_theta0 - sklearn_theta0)}\")\n",
        "print(f\"La diferencia entre scikit y el codigo propio en el theta1 es {abs(rl_theta1 - sklearn_theta1)}\")"
      ],
      "metadata": {
        "id": "cK7FV37oxDoO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}